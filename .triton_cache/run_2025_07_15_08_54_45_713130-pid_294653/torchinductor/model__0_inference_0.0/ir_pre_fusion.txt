op0: SchedulerNode(MultiTemplateBuffer)
op0.writes = [MemoryDep('buf0', c0, {c0: 160})]
op0.unmet_dependencies = []
op0.met_dependencies = 
    [   MemoryDep('arg0_1', c0 + 10*c1, {c0: 10, c1: 5}),
        MemoryDep('arg2_1', c0, {c0: 320})]
op0.outputs = [
    buf0: MultiTemplateBuffer
    buf0.layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
    buf0.users = [
        NodeUser(node=SchedulerNode(name='op1'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op2'), can_inplace=True, is_weak=False),
    ]
]
op0.group.device = cuda:0
op0.group.iteration = (160, 1)
op0.sizes = ([32, 5], ())
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[32, 10], stride=[10, 1])
arg0_1_layout = FixedLayout('cuda:0', torch.float32, size=[5, 10], stride=[10, 1])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])


op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', c0, {c0: 32})]
op1.unmet_dependencies = 
    [   MemoryDep('buf0', 5*c0 + 1, {c0: 32}),
        MemoryDep('buf0', 5*c0 + 2, {c0: 32}),
        MemoryDep('buf0', 5*c0 + 3, {c0: 32}),
        MemoryDep('buf0', 5*c0 + 4, {c0: 32}),
        MemoryDep('buf0', 5*c0, {c0: 32})]
op1.met_dependencies = 
    [   MemoryDep('arg1_1', 0, {}),
        MemoryDep('arg1_1', 1, {}),
        MemoryDep('arg1_1', 2, {}),
        MemoryDep('arg1_1', 3, {}),
        MemoryDep('arg1_1', 4, {})]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda:0', torch.float32, size=[32, 1], stride=[1, 32])
    buf1.users = [NodeUser(node=SchedulerNode(name='op2'), can_inplace=False, is_weak=False)]
]
op1.group.device = cuda:0
op1.group.iteration = (32, 1)
op1.sizes = ([32], [])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[5], stride=[1])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[5], stride=[1])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[5], stride=[1])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[5], stride=[1])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[5], stride=[1])
buf1_layout = FixedLayout('cuda:0', torch.float32, size=[32, 1], stride=[1, 32])
class op1_loop_body:
    var_ranges = {p0: 32}
    index0 = 5*p0
    index1 = 0
    index2 = 5*p0 + 1
    index3 = 1
    index4 = 5*p0 + 2
    index5 = 2
    index6 = 5*p0 + 3
    index7 = 3
    index8 = 5*p0 + 4
    index9 = 4
    index10 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf0', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg1_1', get_index_1)
        add = ops.add(load, load_1)
        relu = ops.relu(add)
        mul = ops.mul(relu, relu)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('buf0', get_index_2)
        get_index_3 = self.get_index('index3')
        load_3 = ops.load('arg1_1', get_index_3)
        add_1 = ops.add(load_2, load_3)
        relu_1 = ops.relu(add_1)
        mul_1 = ops.mul(relu_1, relu_1)
        add_2 = ops.add(mul, mul_1)
        get_index_4 = self.get_index('index4')
        load_4 = ops.load('buf0', get_index_4)
        get_index_5 = self.get_index('index5')
        load_5 = ops.load('arg1_1', get_index_5)
        add_3 = ops.add(load_4, load_5)
        relu_2 = ops.relu(add_3)
        mul_2 = ops.mul(relu_2, relu_2)
        add_4 = ops.add(add_2, mul_2)
        get_index_6 = self.get_index('index6')
        load_6 = ops.load('buf0', get_index_6)
        get_index_7 = self.get_index('index7')
        load_7 = ops.load('arg1_1', get_index_7)
        add_5 = ops.add(load_6, load_7)
        relu_3 = ops.relu(add_5)
        mul_3 = ops.mul(relu_3, relu_3)
        add_6 = ops.add(add_4, mul_3)
        get_index_8 = self.get_index('index8')
        load_8 = ops.load('buf0', get_index_8)
        get_index_9 = self.get_index('index9')
        load_9 = ops.load('arg1_1', get_index_9)
        add_7 = ops.add(load_8, load_9)
        relu_4 = ops.relu(add_7)
        mul_4 = ops.mul(relu_4, relu_4)
        add_8 = ops.add(add_6, mul_4)
        constant = ops.constant(5.0, torch.float32)
        truediv = ops.truediv(add_8, constant)
        get_index_10 = self.get_index('index10')
        store = ops.store('buf1', get_index_10, truediv, None)
        return store


op2: SchedulerNode(ComputedBuffer)
op2.writes = [MemoryDep('buf2', c0, {c0: 160})]
op2.unmet_dependencies = [MemoryDep('buf0', c0, {c0: 160}), MemoryDep('buf1', c0, {c0: 32})]
op2.met_dependencies = 
    [   MemoryDep('arg1_1', c1, {c0: 32, c1: 5}),
        MemoryDep('arg3_1', c1, {c0: 32, c1: 5})]
op2.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
    buf2.users = [NodeUser(node=SchedulerNode(name='op3'), can_inplace=False, is_weak=False)]
]
op2.group.device = cuda:0
op2.group.iteration = (160, 1)
op2.sizes = ([32, 5], [])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[5], stride=[1])
buf1_layout = FixedLayout('cuda:0', torch.float32, size=[32, 1], stride=[1, 32])
arg3_1_layout = FixedLayout('cuda:0', torch.float32, size=[5], stride=[1])
buf2_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
class op2_loop_body:
    var_ranges = {p0: 32, p1: 5}
    index0 = 5*p0 + p1
    index1 = p1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf0', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg1_1', get_index_1)
        add = ops.add(load, load_1)
        relu = ops.relu(add)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('buf1', get_index_2)
        constant = ops.constant(1.1920928955078125e-07, torch.float32)
        add_1 = ops.add(load_2, constant)
        rsqrt = ops.rsqrt(add_1)
        mul = ops.mul(relu, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg3_1', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf2', get_index_4, mul_1, None)
        return store


op3: SchedulerNode(MultiTemplateBuffer)
op3.writes = [MemoryDep('buf3', c0, {c0: 64})]
op3.unmet_dependencies = [MemoryDep('buf2', c0, {c0: 160})]
op3.met_dependencies = 
    [   MemoryDep('arg4_1', c0 + 5*c1, {c0: 5, c1: 2}),
        MemoryDep('arg5_1', c1, {c0: 32, c1: 2})]
op3.outputs = [
    buf3: MultiTemplateBuffer
    buf3.layout = FixedLayout('cuda:0', torch.float32, size=[32, 2], stride=[2, 1])
    buf3.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op3.group.device = cuda:0
op3.group.iteration = (64, 1)
op3.sizes = ([32, 2], ())
arg5_1_layout = FixedLayout('cuda:0', torch.float32, size=[2], stride=[1])
buf2_layout = FixedLayout('cuda:0', torch.float32, size=[32, 5], stride=[5, 1])
arg4_1_layout = FixedLayout('cuda:0', torch.float32, size=[2, 5], stride=[5, 1])
buf3_layout = FixedLayout('cuda:0', torch.float32, size=[32, 2], stride=[2, 1])


